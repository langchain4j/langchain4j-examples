########## CHAT MODELS ##########

# OpenAI
langchain4j.chat-model.provider=openai
langchain4j.chat-model.openai.api-key=demo
langchain4j.chat-model.openai.model-name=gpt-3.5-turbo
langchain4j.chat-model.openai.temperature=0.0
#langchain4j.chat-model.openai.top-p=1.0
#langchain4j.chat-model.openai.max-tokens=100
#langchain4j.chat-model.openai.presence-penalty=0.0
#langchain4j.chat-model.openai.frequency-penalty=0.0
#langchain4j.chat-model.openai.timeout=PT10S
#langchain4j.chat-model.openai.max-retries=3
#langchain4j.chat-model.openai.log-requests=true
#langchain4j.chat-model.openai.log-responses=true

# HuggingFace
#langchain4j.chat-model.provider=huggingface
#langchain4j.chat-model.huggingface.access-token=hf_... you can generate it here: https://huggingface.co/settings/tokens
#langchain4j.chat-model.huggingface.model-id=tiiuae/falcon-7b-instruct
#langchain4j.chat-model.huggingface.timeout=PT10S
#langchain4j.chat-model.huggingface.temperature=0.1
#langchain4j.chat-model.huggingface.max-new-tokens=50
#langchain4j.chat-model.huggingface.return-full-text=false
#langchain4j.chat-model.huggingface.wait-for-model=true

# LocalAI
#langchain4j.chat-model.provider=localai
#langchain4j.chat-model.localai.base-url=http://localhost:8080
#langchain4j.chat-model.localai.model-name=orca-mini-3b.ggmlv3.q4_0.bin
#langchain4j.chat-model.localai.temperature=0.0
#langchain4j.chat-model.localai.top-p=1.0
#langchain4j.chat-model.localai.max-tokens=5
#langchain4j.chat-model.localai.timeout=PT60S
#langchain4j.chat-model.localai.max-retries=3
#langchain4j.chat-model.localai.log-requests=true
#langchain4j.chat-model.localai.log-responses=true


########## EMBEDDING MODELS ##########

# OpenAI
langchain4j.embedding-model.provider=openai
langchain4j.embedding-model.openai.api-key=demo
#langchain4j.embedding-model.openai.model-name=text-embedding-ada-002
#langchain4j.embedding-model.openai.timeout=PT10S
#langchain4j.embedding-model.openai.max-retries=3
#langchain4j.embedding-model.openai.log-requests=true
#langchain4j.embedding-model.openai.log-responses=true

# HuggingFace
#langchain4j.embedding-model.provider=huggingface
#langchain4j.embedding-model.huggingface.access-token=hf_... you can generate it here: https://huggingface.co/settings/tokens
#langchain4j.embedding-model.huggingface.model-id=sentence-transformers/all-MiniLM-L6-v2
#langchain4j.embedding-model.huggingface.timeout=PT10S
#langchain4j.embedding-model.huggingface.wait-for-model=true

# LocalAI
#langchain4j.embedding-model.provider=localai
#langchain4j.embedding-model.localai.base-url=http://localhost:8080
#langchain4j.embedding-model.localai.model-name=bert
#langchain4j.embedding-model.localai.timeout=PT60S
#langchain4j.embedding-model.localai.max-retries=3
#langchain4j.embedding-model.localai.log-requests=true
#langchain4j.embedding-model.localai.log-responses=true


########## MODERATION MODELS ##########

# OpenAI Moderation Model
#langchain4j.moderation-model.provider=openai
#langchain4j.moderation-model.openai.api-key=sk-... you can generate it here: https://platform.openai.com/account/api-keys
#langchain4j.moderation-model.openai.model-name=text-moderation-latest
#langchain4j.moderation-model.openai.timeout=PT10S
#langchain4j.moderation-model.openai.log-requests=true
#langchain4j.moderation-model.openai.log-responses=true


########## LOGGING ##########

logging.level.dev.langchain4j=DEBUG
logging.level.dev.ai4j.openai4j=DEBUG